{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f5240a-e773-487c-a562-2027efe70233",
   "metadata": {},
   "source": [
    "IA & Data science (LU3IN0226) -- 2024-2025\n",
    "--------\n",
    "*&copy; Equipe pédagogique: Christophe Marsala, Olivier Schwander, Jean-Noël Vittaut.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50018277-b782-446f-9446-0a7163f25315",
   "metadata": {},
   "source": [
    "# Mini-projet final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a8643-d3b4-42dd-acdf-31e374f15db6",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"RED\">**[Q]**</font> **Indiquer dans la boîte ci-dessous vos noms et prénoms :**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7f75b3-b8fe-4c1e-a5b4-693fb90bc1c6",
   "metadata": {},
   "source": [
    "- Ekaterina BOGUSH\n",
    "- Amélie CHU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f770d35b-fb4c-42ea-8f57-48921b2b82a5",
   "metadata": {},
   "source": [
    "Ce projet peut être fait en binôme (et c'est fortement conseillé) ou tout seul.\n",
    "\n",
    "Le nom de chaque membre du binôme doit être indiqué, et <u>**un seul rendu sur un des deux comptes Moodle doit être fait**</u>.\n",
    "\n",
    "Les groupes de plus de 2 personnes ne sont pas autorisés.\n",
    "\n",
    "**La dernière séance de TD-TME11 de votre groupe sera réservée pour travailler sur ce mini-projet.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efc44f2-00f2-4679-b0c1-ea4366a6ad80",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> **Renommer ce fichier ipython**\n",
    "\n",
    "**Nom à donner au fichier à poster** : *projet-Nom1_Nom2.ipynb* \n",
    "- *Nom1* et *Nom2* : noms des membres du binôme\n",
    "- ne pas compresser ou faire une archive: il faut rendre le fichier ipython tel quel, éventuellement, si vous avez d'autres fichiers vous les rendez séparément.\n",
    "\n",
    "**Le compte-rendu est soumis sur la page Moodle.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb05912-5ec9-4635-83b9-f056a3429361",
   "metadata": {},
   "source": [
    "# Projet 2 - avril-mai 2025\n",
    "\n",
    "\n",
    "<font size=\"+1\" color=\"RED\"><b>Date de rendu : au plus tard le lundi 19 mai 2025, avant 11h</b></font>\n",
    "    \n",
    "<b>Attention! le site Moodle ferme à 11h pile !</b> prévoyez de vous y connecter au moins 15mn avant la fermeture...\n",
    "<b>Il n'y aura pas de prolongation possible.</b>\n",
    "\n",
    "Vous devez compléter ce notebook en rajoutant vos expérimentations avec vos algorithmes d'apprentissage sur les données fournies dans le répertoire `data`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ad36e1-f91f-41a8-bea8-da028d30e6c4",
   "metadata": {},
   "source": [
    "## Travail à faire\n",
    "\n",
    "Appliquer les algorithmes d'apprentissage vus en cours sur les données comme décrit ci-dessous afin de mettre en évidence des résultats intéressants.\n",
    "\n",
    "\n",
    "## Compte-rendu demandé\n",
    "Ce qui doit être remis avant la date limite : un fichier archive (`.tar`, `.tgz`, ou `.zip` uniquement) contenant:\n",
    "- ce **notebook** complété. Il doit pouvoir être exécuté sans autre apport (pensez à vous en assurer avant de le rendre). \n",
    "- votre **librairie iads** sous la forme d'une archive avec votre répertoire `iads/` contenant tous les fichiers nécessaires \n",
    "- un **poster** sous la forme d'un fichier PDF dont le nom est de la forme: *tme11-Nom1_Nom2.pdf* qui correspond à un poster décrivant l'ensemble des expérimentations menées et les résultats obtenus.\n",
    "\n",
    "\n",
    "<b>IMPORTANT</b>: \n",
    "- Les <u>fichiers de données ne doivent pas être inclus dans votre archive</u> ! \n",
    "- Pensez à vérifier que votre archive contient bien tous les fichiers demandés et **seulement** les fichiers demandés.\n",
    "- **Tous les fichiers demandés doivent être soumis avant la date limite*, le jour de la soutenance, vous pourrez fournir des versions (légèrement) modifiées.\n",
    "\n",
    "## Soutenance des projets\n",
    "La soutenance aura lieu le <font size=\"+1\" color=\"RED\">**mardi 20 mai 2025**</font>, à partir de 9h. Un ordre de passage ainsi que la salle de TME où aura lieu les soutenances seront affichées sur le Moodle la veille (la remise d'un compte-rendu avant lundi 19 mai 11h est obligatoire pour être autorisé à passer une soutenance).\n",
    "\n",
    "La <b>soutenance est obligatoire</b> : tout projet pour lequel une soutenance n'a pas eu lieu sera noté $0$.\n",
    "\n",
    "Modalités de la soutenance:\n",
    "- durée de la soutenance : 10 mn pour un binôme, 7 mn pour un monôme ;\n",
    "- elle a lieu devant un ordinateur avec le notebook et le poster comme support ;\n",
    "    - elle commence par une rapide présentation des expérimentations réalisées et résultats obtenus (max. 4 à 5mns)\n",
    "    - puis elle se poursuit par des questions posées individuellement aux membres du binômes sur les expériences ou le code python réalisé.\n",
    "- la note de soutenance est individuelle pour chaque membre d'un binôme.\n",
    "\n",
    "\n",
    "**Très important** : les fichiers de données doivent être placés de façon à respecter la structure de fichiers suivante :\n",
    "\n",
    "          --iads/\n",
    "              -- Classifiers.py\n",
    "              -- etc.\n",
    "          -- MiniProjet/\n",
    "              -- ce_notebook.ipynb\n",
    "\n",
    "Les données seront chargées par les commandes de chargement des données fournies dans ce notebook (ci-dessous).\n",
    "\n",
    "Dans le notebook que vous rendrez, le chargement des fichiers de données doit considérer cette arborescence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "64e0796c-a140-4bbf-a11a-58f40b9e0497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Importation de librairies standards:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from string import punctuation\n",
    "from unidecode import unidecode \n",
    "%matplotlib inline  \n",
    "\n",
    "# un nouvel import utile pour la 3D:\n",
    "from matplotlib import cm\n",
    "\n",
    "# Les instructions suivantes sont TRES utiles pour recharger automatiquement \n",
    "# le code modifié dans les librairies externes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Pour mesurer le temps\n",
    "import time\n",
    "\n",
    "# Importation de votre librairie iads:\n",
    "# La ligne suivante permet de préciser le chemin d'accès à la librairie iads\n",
    "import sys\n",
    "sys.path.append('../')   # iads doit être dans le répertoire père du répertoire courant !\n",
    "\n",
    "# Importation de la librairie iads\n",
    "import iads as iads\n",
    "\n",
    "# importation de Classifiers\n",
    "from iads import Classifiers as classif\n",
    "\n",
    "# importation de utils\n",
    "from iads import utils as ut\n",
    "\n",
    "# importation de evaluation\n",
    "from iads import evaluation as ev\n",
    "\n",
    "# importation de Clustering\n",
    "from iads import Clustering as clust\n",
    "\n",
    "# sparse matrix\n",
    "from scipy.sparse import csr_array\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# commande TRES utile pour recharger automatiquement le code que vous modifiez dans les modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca98bdab-80fe-44a1-8057-d027925d8d0f",
   "metadata": {},
   "source": [
    "## Données pour le projet : 20newsgroups\n",
    "\n",
    "Les données sont fournies dans le fichier CSV `20newsgroups.csv` contenu dans l'archive. Une documentation sur ces données peut être consultée sur la <a href=\"http://qwone.com/~jason/20Newsgroups/\" target=\"NEW\">page ScikitLearn</a>.\n",
    "Ces données sont des dépêches issues de 20 groupes de discussions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a483d33-8e89-4f7c-8525-5dfaae092e86",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "49b32889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18841</th>\n",
       "      <td>DN&gt; From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18842</th>\n",
       "      <td>\\nNot in isolated ground recepticles (usually ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18843</th>\n",
       "      <td>I just installed a DX2-66 CPU in a clone mothe...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18844</th>\n",
       "      <td>\\nWouldn't this require a hyper-sphere.  In 3-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18845</th>\n",
       "      <td>After a tip from Gary Crum (crum@fcom.cc.utah....</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18846 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                messages  target\n",
       "0      \\n\\nI am sure some bashers of Pens fans are pr...      10\n",
       "1      My brother is in the market for a high-perform...       3\n",
       "2      \\n\\n\\n\\n\\tFinally you said what you dream abou...      17\n",
       "3      \\nThink!\\n\\nIt's the SCSI card doing the DMA t...       3\n",
       "4      1)    I have an old Jasmine drive which I cann...       4\n",
       "...                                                  ...     ...\n",
       "18841  DN> From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...      13\n",
       "18842  \\nNot in isolated ground recepticles (usually ...      12\n",
       "18843  I just installed a DX2-66 CPU in a clone mothe...       3\n",
       "18844  \\nWouldn't this require a hyper-sphere.  In 3-...       1\n",
       "18845  After a tip from Gary Crum (crum@fcom.cc.utah....       7\n",
       "\n",
       "[18846 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_df = pd.read_csv(\"data/20newsgroups.csv\")\n",
    "newsgroups_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9453549-a545-468d-a0a9-0caa750630ea",
   "metadata": {},
   "source": [
    "### Prétraitement\n",
    "\n",
    "Dans un premier temps, vous devez appliquer les étapes de prétraitements vues dans le TME 6. Pour le nettoyage, la liste des mots inutiles (stopwords) est fournie dans le fichier `stopwords.csv` de l'archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9462a8e5-061c-41ae-ad3e-16a95d84db64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>you're</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>yours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>yourself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>yourselves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>you've</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       stopword\n",
       "0             a\n",
       "1         about\n",
       "2         above\n",
       "3         after\n",
       "4         again\n",
       "..          ...\n",
       "193      you're\n",
       "194       yours\n",
       "195    yourself\n",
       "196  yourselves\n",
       "197      you've\n",
       "\n",
       "[198 rows x 1 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_df = pd.read_csv(\"data/stopwords.csv\")\n",
    "stopwords = stop_words_df[\"stopword\"].values.tolist()\n",
    "stop_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b6303913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nans 380\n"
     ]
    }
   ],
   "source": [
    "# Delete nans\n",
    "print(\"Number of Nans\", newsgroups_df[newsgroups_df[\"messages\"].isna()].shape[0])\n",
    "newsgroups_df = newsgroups_df[~newsgroups_df[\"messages\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8203b5",
   "metadata": {},
   "source": [
    "1. Mettre toutes les lettre en miniscules\n",
    "2. Enlever punctuation (sauf ')\n",
    "3. Enlever stopwords ***si nécessaire***\n",
    "4. Enlever les mots qui ne contient que les chiffres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e05d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(news:pd.DataFrame, stopwords:list[str], delete_stopwords:bool=True, delete_digits:bool=True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fait un prétraitement de la base de données 'news' :\n",
    "        1. Supprime les NaNs\n",
    "        2. Convertit unicode en ascii\n",
    "        3. Supprime '\\n \\r \\t' et toute la punctuation sauf '\n",
    "        4. Supprime les stopwords [si nécessaire]\n",
    "        5. Supprime les chiffres qui sont seuls (sans lettres à coté) [si nécessaire]\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        news : Database qui contient la base de données sur 'news'. Colonne 'messages' doit être présent.\n",
    "        stopwords : Liste des stopwords\n",
    "        delete_stopwords : Si True, alors les stopwords seront enlevés. Si False, ils seront préservés.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        Dataframe 'news' nettoyé selon les 4 étapes ci-dessus\n",
    "            (et avec la colonne 'Message index' ajouté --> TO DO : see if useful later. If not, delete).\n",
    "    \"\"\"\n",
    "\n",
    "    def del_stopwords(tokenized_msg:list[str]) -> list[str]:\n",
    "        return [word for word in tokenized_msg if word not in stopwords and word != \"\\'\"]\n",
    "\n",
    "    def del_digits(tokenized_msg:list[str]) -> list[str]:\n",
    "        return [word for word in tokenized_msg if not word.isdigit()]\n",
    "     \n",
    "    # To be able to implode afterwards if necessary --> see later if it is useful\n",
    "    news = news.reset_index().rename(columns={\"index\":\"Message index\"})\n",
    "\n",
    "    # Delete NaNs\n",
    "    print(\"Number of Nans\", news[\"messages\"].isna().size)\n",
    "    news.loc[:, \"messages\"] = news[~news[\"messages\"].isna()]\n",
    "\n",
    "    # Convert unicode to ascii. Delete \\n \\r \\t\n",
    "    news.loc[:, \"messages\"] = news[\"messages\"].apply(unidecode).str.replace(r'[\\n\\r\\t]', '', regex=True)\n",
    "    \n",
    "    # Delete all punctuation but '\n",
    "    punc = punctuation.replace('\\'', '')\n",
    "    trans_table = str.maketrans(punc, ' ' * len(punc))\n",
    "    news.loc[:, \"messages\"] = news[\"messages\"].str.lower().str.translate(trans_table).str.split()\n",
    "\n",
    "    # Delete stopwords if necessary\n",
    "    if delete_stopwords:\n",
    "        news.loc[:, \"messages\"] = news[\"messages\"].apply(del_stopwords)\n",
    "    \n",
    "    if delete_digits:\n",
    "        news.loc[:, \"messages\"] = news[\"messages\"].apply(del_digits)\n",
    "\n",
    "    return news\n",
    "\n",
    "def get_corpus(news:pd.DataFrame) -> list[str]:\n",
    "    return news[\"messages\"].explode().unique()\n",
    "\n",
    "def get_bow_vect(news:pd.DataFrame, corpus:list[str], binary=False) -> csr_array:\n",
    "   vectorizer = CountVectorizer(vocabulary=corpus, binary=binary)\n",
    "   return vectorizer.transform(news[\"messages\"])\n",
    "\n",
    "def get_tfidf_vect(news:pd.DataFrame, corpus:list[str]) -> csr_array:\n",
    "    vectorizer = TfidfVectorizer(vocabulary=corpus)\n",
    "    return vectorizer.fit_transform(news[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060fe888",
   "metadata": {},
   "source": [
    "### Lemmatisation et le tri supplémentaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2a18f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nans 18466\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message index</th>\n",
       "      <th>target</th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>sure pen fan pretty confused lackof kind post ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>brother market high performance video card loc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>finally said dream mediterranean new area grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>think scsi card dma transfer disk scsi card dm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>old drive cannot use new system understanding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18265</th>\n",
       "      <td>18841</td>\n",
       "      <td>13</td>\n",
       "      <td>edu david consultation cheaper scan also bette...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18266</th>\n",
       "      <td>18842</td>\n",
       "      <td>12</td>\n",
       "      <td>isolated ground usually unusual color yellow o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18267</th>\n",
       "      <td>18843</td>\n",
       "      <td>3</td>\n",
       "      <td>installed dx2 cpu clone motherboard tried moun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18268</th>\n",
       "      <td>18844</td>\n",
       "      <td>1</td>\n",
       "      <td>require sphere space point sphere far see unle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18269</th>\n",
       "      <td>18845</td>\n",
       "      <td>7</td>\n",
       "      <td>tip gary utah edu got pontiac system customer ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18270 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Message index  target  \\\n",
       "0                  0      10   \n",
       "1                  1       3   \n",
       "2                  2      17   \n",
       "3                  3       3   \n",
       "4                  4       4   \n",
       "...              ...     ...   \n",
       "18265          18841      13   \n",
       "18266          18842      12   \n",
       "18267          18843       3   \n",
       "18268          18844       1   \n",
       "18269          18845       7   \n",
       "\n",
       "                                                messages  \n",
       "0      sure pen fan pretty confused lackof kind post ...  \n",
       "1      brother market high performance video card loc...  \n",
       "2      finally said dream mediterranean new area grea...  \n",
       "3      think scsi card dma transfer disk scsi card dm...  \n",
       "4      old drive cannot use new system understanding ...  \n",
       "...                                                  ...  \n",
       "18265  edu david consultation cheaper scan also bette...  \n",
       "18266  isolated ground usually unusual color yellow o...  \n",
       "18267  installed dx2 cpu clone motherboard tried moun...  \n",
       "18268  require sphere space point sphere far see unle...  \n",
       "18269  tip gary utah edu got pontiac system customer ...  \n",
       "\n",
       "[18270 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_no_stopwords = clean_str(newsgroups_df, stopwords, delete_stopwords=True, delete_digits=True)\n",
    "\n",
    "words = news_no_stopwords.explode(\"messages\")\n",
    "words = words[~words[\"messages\"].isna()]\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "unique_words = pd.DataFrame(data={\"word\":words[\"messages\"].unique()})\n",
    "unique_words[\"lemma\"] = unique_words[\"word\"].apply(wnl.lemmatize)\n",
    "words = words.merge(unique_words, left_on=\"messages\", right_on=\"word\").drop(columns=\"word\")\n",
    "\n",
    "# Min length = 3\n",
    "words = words[words[\"lemma\"].apply(len) > 2] \n",
    "\n",
    "# Min count = 10\n",
    "count = words[\"lemma\"].value_counts()\n",
    "words = words[words[\"lemma\"].isin(count[count >= 10].index)]\n",
    "\n",
    "corpus = words[\"lemma\"].unique()\n",
    "messages = words.groupby(\"Message index\")[\"lemma\"].apply(\" \".join).reset_index()\n",
    "news_no_stopwords = news_no_stopwords[[\"Message index\", \"target\"]].merge(messages, on=\"Message index\").rename(columns={\"lemma\":\"messages\"})\n",
    "news_no_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bf221f",
   "metadata": {},
   "source": [
    "# Apprentissage supervisé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bdd526",
   "metadata": {},
   "source": [
    "### Dataset : **sans** stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4546c0",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4272190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_labels = news_no_stopwords[\"target\"].values\n",
    "n_classes = news_no_stopwords[\"target\"].nunique()\n",
    "\n",
    "# BoW binaire\n",
    "news_desc = get_bow_vect(news_no_stopwords, corpus, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "38ed6421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "971756"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_desc.data.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0df0788",
   "metadata": {},
   "source": [
    "#### KNN multi-classe [distance **euclidienne**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "20b37dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ affichage validation croisée\n",
      "crossval strat ok\n",
      "Itération 0: taille de base app.=14625\ttaille base test=3645\tTaux de bonne classif: 0.1684\n",
      "crossval strat ok\n",
      "Itération 1: taille de base app.=14625\ttaille base test=3645\tTaux de bonne classif: 0.1668\n",
      "crossval strat ok\n",
      "Itération 2: taille de base app.=14625\ttaille base test=3645\tTaux de bonne classif: 0.1720\n",
      "crossval strat ok\n",
      "Itération 3: taille de base app.=14625\ttaille base test=3645\tTaux de bonne classif: 0.1695\n",
      "crossval strat ok\n",
      "Itération 4: taille de base app.=14625\ttaille base test=3645\tTaux de bonne classif: 0.1438\n",
      "------ fin affichage validation croisée\n",
      "Results [0.16844993141289438, 0.16680384087791494, 0.1720164609053498, 0.16954732510288065, 0.14375857338820303]\n",
      "Mean accuracy 0.1641, std : 0.0103\n",
      "Time 71.8959150314331\n"
     ]
    }
   ],
   "source": [
    "classifier_knn = classif.ClassifierKNN_MC(news_desc.shape[1], k=10, C=n_classes, dist_type=\"euclidean\")\n",
    "\n",
    "start = time.time()\n",
    "(res_all, res_mean, res_std) = ev.validation_croisee(classifier_knn, (news_desc, news_labels), 5, True)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Results\", res_all)\n",
    "print(f\"Mean accuracy {res_mean:.4f}, std : {res_std:.4f}\")\n",
    "print(\"Time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6d42562c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ affichage validation croisée\n",
      "crossval strat ok\n",
      "Itération 0: taille de base app.=14625\ttaille base test=3645\tTaux de bonne classif: 0.5498\n",
      "crossval strat ok\n",
      "Itération 1: taille de base app.=14625\ttaille base test=3645\tTaux de bonne classif: 0.5575\n",
      "crossval strat ok\n",
      "Itération 2: taille de base app.=14625\ttaille base test=3645\tTaux de bonne classif: 0.5517\n",
      "crossval strat ok\n",
      "Itération 3: taille de base app.=14625\ttaille base test=3645\tTaux de bonne classif: 0.5465\n",
      "crossval strat ok\n",
      "Itération 4: taille de base app.=14625\ttaille base test=3645\tTaux de bonne classif: 0.5503\n",
      "------ fin affichage validation croisée\n",
      "Results [0.5497942386831276, 0.5574759945130315, 0.5517146776406036, 0.5465020576131687, 0.5503429355281207]\n",
      "Mean accuracy 0.5512, std : 0.0036\n",
      "Time 106.69541883468628\n"
     ]
    }
   ],
   "source": [
    "classifier_knn = classif.ClassifierKNN_MC(news_desc.shape[1], k=10, C=n_classes, dist_type=\"cosine\")\n",
    "\n",
    "start = time.time()\n",
    "(res_all, res_mean, res_std) = ev.validation_croisee(classifier_knn, (news_desc, news_labels), 5, True)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Results\", res_all)\n",
    "print(f\"Mean accuracy {res_mean:.4f}, std : {res_std:.4f}\")\n",
    "print(\"Time\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de698f69",
   "metadata": {},
   "source": [
    "#### Perceptron (avec biais) --> 1 itération (entraînement est trop long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1619617e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sur test 0.6776406035665294\n",
      "Time 178.58149313926697\n"
     ]
    }
   ],
   "source": [
    "classifier_perceptron = classif.ClassifierPerceptron(news_desc.shape[1], learning_rate=0.01, init=False, sparse=True)\n",
    "multiOAA = classif.ClassifierMultiOAA(classifier_perceptron, np.unique(news_labels))\n",
    "\n",
    "train_desc, train_label, test_desc, test_label = ev.crossval_strat(news_desc, news_labels, 5, 1)\n",
    "\n",
    "start = time.time()\n",
    "multiOAA.train(train_desc, train_label)\n",
    "accuracy =  multiOAA.accuracy(test_desc, test_label)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Accuracy sur test\", accuracy)\n",
    "print(\"Time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3aaf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06815712, 0.58761488, 0.09510722, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.09313443, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW binaire\n",
    "#news_desc = get_bow_vect(news_no_stopwords, corpus, False)\n",
    "news_desc = get_tfidf_vect(news_no_stopwords, corpus)\n",
    "\n",
    "news_desc.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6ffe1c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9f2d359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_desc, train_label, test_desc, test_label = ev.crossval_strat(news_desc, news_labels, 5, 1)\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion=\"entropy\", splitter=\"best\", min_samples_split=2, min_impurity_decrease=0.0)\n",
    "tree = tree.fit(train_desc, train_label)\n",
    "\n",
    "predictions = tree.predict(test_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "786b98f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39451303155006856"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((predictions == test_label) == True)[0].size / test_label.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cabf183-5055-4a78-a485-34e57e33ad1d",
   "metadata": {},
   "source": [
    "## Tâches à réaliser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a96998-c20b-4893-bb69-b5d0031474bb",
   "metadata": {},
   "source": [
    "### Apprentissage supervisé\n",
    "\n",
    "*Tâches*: évaluation d'algorithmes et de représentations des données.\n",
    "- classification binaire\n",
    "- classification multi-classe\n",
    "\n",
    "*Etudes suggérées*:\n",
    "- représentations des données\n",
    "    - avec ou sans suppression des stopwords\n",
    "    - différentes représentations: bag-of-words binaire, avec comptage, avec fréquences, avec tfidf\n",
    "- différents classifiers:\n",
    "    - perceptron,\n",
    "    - k-plus proches voisins avec distance euclidienne,\n",
    "    - k-plus proches voisins avec distance cosinus (cf. TD),\n",
    "    - Naives Bayes,\n",
    "    - arbres de décision\n",
    "- analyse des résultats:\n",
    "    - accuracy, temps d'exécutions\n",
    "    - score fold par fold\n",
    "    - matrice de confusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143ad533",
   "metadata": {},
   "source": [
    "### Apprentissage non-supervisé\n",
    "\n",
    "*Tâche*: vérifier que le découpage a du sens par rapport aux groupes fournis. \n",
    "\n",
    "*Etudes suggérées*:\n",
    "- étudier l'application d'un clustering hiérarchique et son résultat;\n",
    "- étudier les résultats de l'application de l'algorithme des k-moyennes, pour différentes valeurs de k;\n",
    "- proposer des évaluations des clusters trouvés afin de mettre en évidence les plus intéressants:\n",
    "    - en utilisant les indices d'évaluation présentés en cours;\n",
    "    - en comparant par diverses méthodes les clusters trouvés avec les vrais labels des classes (targets y).\n",
    "- proposer une visualisation des résultats obtenus\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a907d27",
   "metadata": {},
   "source": [
    "## Poster à rendre dans le compte-rendu (format PDF)\n",
    "\n",
    "Votre poster doit décrire de façon synthétique **l'ensemble des expérimentations** menées sur les données, les résultats obtenus en apprentissage supervisé et en apprentissage non-supervisé ainsi que les conclusions/bilans que vous tirez de ces expérimentations (ie. ce que vous avez appris sur ces données).\n",
    "\n",
    "*Remarque*: vous devez indiquer vos noms/prénoms et groupe (1, 2, ou 3) sur le poster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8873bae2-24cd-4dd3-b89e-887a28f7d6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
